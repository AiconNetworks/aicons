{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "notebook_dir = Path.cwd()\n",
    "project_root = notebook_dir.parent\n",
    "sys.path.append(str(project_root))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break Aicon 4 Ads (BAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required classes\n",
    "from aicons.bayesbrainGPT.sensors.meta_s.meta_ads_sales_sensor import MetaAdsSalesSensor\n",
    "from aicons.definitions.simple_bad_aicon import SimpleBadAIcon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage\n",
    "Section 1: Create and Initialize the AIcon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mock data generated with the following ads:\n",
      "  - Ad ID: 1_1\n",
      "  - Ad ID: 1_2\n",
      "  - Ad ID: 2_1\n",
      "  - Ad ID: 2_2\n",
      "Auto-creating missing factor: purchases (continuous)\n",
      "Creating continuous factor with TensorFlow: purchases\n",
      "Added continuous factor with TensorFlow distribution: purchases\n",
      "Auto-creating missing factor: add_to_carts (continuous)\n",
      "Creating continuous factor with TensorFlow: add_to_carts\n",
      "Added continuous factor with TensorFlow distribution: add_to_carts\n",
      "Auto-creating missing factor: initiated_checkouts (continuous)\n",
      "Creating continuous factor with TensorFlow: initiated_checkouts\n",
      "Added continuous factor with TensorFlow distribution: initiated_checkouts\n",
      "Auto-creating missing factor: ad_*_purchases (continuous)\n",
      "Creating continuous factor with TensorFlow: ad_*_purchases\n",
      "Added continuous factor with TensorFlow distribution: ad_*_purchases\n",
      "Auto-creating missing factor: ad_*_add_to_carts (continuous)\n",
      "Creating continuous factor with TensorFlow: ad_*_add_to_carts\n",
      "Added continuous factor with TensorFlow distribution: ad_*_add_to_carts\n",
      "Auto-creating missing factor: ad_*_initiated_checkouts (continuous)\n",
      "Creating continuous factor with TensorFlow: ad_*_initiated_checkouts\n",
      "Added continuous factor with TensorFlow distribution: ad_*_initiated_checkouts\n",
      "Auto-creating missing factor: ad_*_impressions (continuous)\n",
      "Creating continuous factor with TensorFlow: ad_*_impressions\n",
      "Added continuous factor with TensorFlow distribution: ad_*_impressions\n",
      "Auto-creating missing factor: ad_*_clicks (continuous)\n",
      "Creating continuous factor with TensorFlow: ad_*_clicks\n",
      "Added continuous factor with TensorFlow distribution: ad_*_clicks\n",
      "Auto-creating missing factor: ad_*_spend (continuous)\n",
      "Creating continuous factor with TensorFlow: ad_*_spend\n",
      "Added continuous factor with TensorFlow distribution: ad_*_spend\n",
      "Registered TFSensor: meta_ads (type: MetaAdsSalesSensor)\n",
      "\n",
      "Updating AIcon with sensor data...\n",
      "Mapping observation: purchases → purchases\n",
      "Mapping observation: add_to_carts → add_to_carts\n",
      "Mapping observation: initiated_checkouts → initiated_checkouts\n",
      "Mapping observation: ad_1_1_purchases → ad_1_1_purchases\n",
      "Mapping observation: ad_1_1_add_to_carts → ad_1_1_add_to_carts\n",
      "Mapping observation: ad_1_1_initiated_checkouts → ad_1_1_initiated_checkouts\n",
      "Mapping observation: ad_1_1_impressions → ad_1_1_impressions\n",
      "Mapping observation: ad_1_1_clicks → ad_1_1_clicks\n",
      "Mapping observation: ad_1_1_spend → ad_1_1_spend\n",
      "Mapping observation: ad_1_2_purchases → ad_1_2_purchases\n",
      "Mapping observation: ad_1_2_add_to_carts → ad_1_2_add_to_carts\n",
      "Mapping observation: ad_1_2_initiated_checkouts → ad_1_2_initiated_checkouts\n",
      "Mapping observation: ad_1_2_impressions → ad_1_2_impressions\n",
      "Mapping observation: ad_1_2_clicks → ad_1_2_clicks\n",
      "Mapping observation: ad_1_2_spend → ad_1_2_spend\n",
      "Mapping observation: ad_2_1_purchases → ad_2_1_purchases\n",
      "Mapping observation: ad_2_1_add_to_carts → ad_2_1_add_to_carts\n",
      "Mapping observation: ad_2_1_initiated_checkouts → ad_2_1_initiated_checkouts\n",
      "Mapping observation: ad_2_1_impressions → ad_2_1_impressions\n",
      "Mapping observation: ad_2_1_clicks → ad_2_1_clicks\n",
      "Mapping observation: ad_2_1_spend → ad_2_1_spend\n",
      "Mapping observation: ad_2_2_purchases → ad_2_2_purchases\n",
      "Mapping observation: ad_2_2_add_to_carts → ad_2_2_add_to_carts\n",
      "Mapping observation: ad_2_2_initiated_checkouts → ad_2_2_initiated_checkouts\n",
      "Mapping observation: ad_2_2_impressions → ad_2_2_impressions\n",
      "Mapping observation: ad_2_2_clicks → ad_2_2_clicks\n",
      "Mapping observation: ad_2_2_spend → ad_2_2_spend\n",
      "Sampling posterior distribution...\n",
      "Warning: Factor ad_1_1_purchases not in state. Skipping.\n",
      "Warning: Factor ad_1_1_add_to_carts not in state. Skipping.\n",
      "Warning: Factor ad_1_1_initiated_checkouts not in state. Skipping.\n",
      "Warning: Factor ad_1_1_impressions not in state. Skipping.\n",
      "Warning: Factor ad_1_1_clicks not in state. Skipping.\n",
      "Warning: Factor ad_1_1_spend not in state. Skipping.\n",
      "Warning: Factor ad_1_2_purchases not in state. Skipping.\n",
      "Warning: Factor ad_1_2_add_to_carts not in state. Skipping.\n",
      "Warning: Factor ad_1_2_initiated_checkouts not in state. Skipping.\n",
      "Warning: Factor ad_1_2_impressions not in state. Skipping.\n",
      "Warning: Factor ad_1_2_clicks not in state. Skipping.\n",
      "Warning: Factor ad_1_2_spend not in state. Skipping.\n",
      "Warning: Factor ad_2_1_purchases not in state. Skipping.\n",
      "Warning: Factor ad_2_1_add_to_carts not in state. Skipping.\n",
      "Warning: Factor ad_2_1_initiated_checkouts not in state. Skipping.\n",
      "Warning: Factor ad_2_1_impressions not in state. Skipping.\n",
      "Warning: Factor ad_2_1_clicks not in state. Skipping.\n",
      "Warning: Factor ad_2_1_spend not in state. Skipping.\n",
      "Warning: Factor ad_2_2_purchases not in state. Skipping.\n",
      "Warning: Factor ad_2_2_add_to_carts not in state. Skipping.\n",
      "Warning: Factor ad_2_2_initiated_checkouts not in state. Skipping.\n",
      "Warning: Factor ad_2_2_impressions not in state. Skipping.\n",
      "Warning: Factor ad_2_2_clicks not in state. Skipping.\n",
      "Warning: Factor ad_2_2_spend not in state. Skipping.\n",
      "Setting up MCMC sampling for 3 observations...\n",
      "Running MCMC sampling...\n",
      "Acceptance rate: 28.20%\n",
      "Sample statistics:\n",
      "  purchases: mean=13.9916, std=3.6869\n",
      "  add_to_carts: mean=107.1946, std=3.6116\n",
      "  initiated_checkouts: mean=-259.0961, std=248.0114\n",
      "\n",
      "Updating state factors from posterior:\n",
      "  purchases: 0.0000 -> 13.9916 (std: 3.6869)\n",
      "  add_to_carts: 0.0000 -> 107.1946 (std: 3.6116)\n",
      "  initiated_checkouts: 0.0000 -> -259.0961 (std: 248.0114)\n",
      "\n",
      "Factors after update:\n",
      "  - ad_*_add_to_carts\n",
      "  - ad_*_clicks\n",
      "  - ad_*_impressions\n",
      "  - ad_*_initiated_checkouts\n",
      "  - ad_*_purchases\n",
      "  - ad_*_spend\n",
      "  - add_to_carts\n",
      "  - initiated_checkouts\n",
      "  - purchases\n",
      "\n",
      "Hierarchical relationships in expected factors:\n",
      "  - purchases (AGGREGATE) sums up ad_*_purchases\n",
      "  - add_to_carts (AGGREGATE) sums up ad_*_add_to_carts\n",
      "  - initiated_checkouts (AGGREGATE) sums up ad_*_initiated_checkouts\n",
      "  - ad_*_purchases (CHILD) contributes to purchases\n",
      "  - ad_*_add_to_carts (CHILD) contributes to add_to_carts\n",
      "  - ad_*_initiated_checkouts (CHILD) contributes to initiated_checkouts\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Fix import path for Babel\n",
    "project_root = \"/Users/infa/Documents/Babel\"\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"Added {project_root} to sys.path\")\n",
    "\n",
    "# Import and reload modules to ensure latest versions\n",
    "import aicons.bayesbrainGPT.sensors.meta_s.meta_ads_sales_sensor\n",
    "import aicons.definitions.simple_bad_aicon\n",
    "\n",
    "# Reload the modules\n",
    "importlib.reload(aicons.bayesbrainGPT.sensors.meta_s.meta_ads_sales_sensor)\n",
    "importlib.reload(aicons.definitions.simple_bad_aicon)\n",
    "\n",
    "# Now import the classes from freshly reloaded modules\n",
    "from aicons.bayesbrainGPT.sensors.meta_s.meta_ads_sales_sensor import MetaAdsSalesSensor\n",
    "from aicons.definitions.simple_bad_aicon import SimpleBadAIcon\n",
    "\n",
    "# Your Facebook API credentials\n",
    "# You'll need to replace these with your actual credentials\n",
    "access_token = \"EAAZAn8wmq1IEBOZCz8oyDZBBgiazAgnQKIoAr4mFTbkV7jxi6t3APzOSxFybXNIkBgwQACdagbs5lFE8tpnNOBOOpWtS3KjZAdf9MNAlySpwEaDrX32oQwUTNmOZAaSXjT5Os5Q8YqRo57tXOUukB7QtcO8nQ8JuqrnnshCr7A0giynZBnJKfuPakrZBWoZD\"  # Replace with your actual token\n",
    "ad_account_id = \"act_252267674525035\"     # Replace with your actual ad account ID\n",
    "campaign_id = \"120218631288730217\"           # The campaign ID you provided\n",
    "\n",
    "# Create the Meta Ads Sensor with real API credentials\n",
    "print(\"Creating Meta Ads Sensor with real API access...\")\n",
    "sensor = MetaAdsSalesSensor(\n",
    "    name=\"meta_ads\",\n",
    "    reliability=0.9,\n",
    "    access_token=access_token,\n",
    "    ad_account_id=ad_account_id,\n",
    "    campaign_id=campaign_id,\n",
    "    api_version=\"v18.0\",          # Using the latest API version\n",
    "    time_granularity=\"hour\"       # Hourly data granularity\n",
    ")\n",
    "\n",
    "# Create and initialize AIcon\n",
    "aicon = SimpleBadAIcon(\"meta_ads_real_data\")\n",
    "\n",
    "# Add the sensor to the AIcon\n",
    "aicon.add_sensor(\"meta_ads\", sensor)\n",
    "\n",
    "# Get initial campaign and ad set information\n",
    "print(\"\\nFetching campaign and ad set information...\")\n",
    "ad_sets = sensor.get_adsets_for_campaign(campaign_id)\n",
    "if ad_sets:\n",
    "    print(f\"Found {len(ad_sets)} ad sets in campaign {campaign_id}\")\n",
    "    for ad_set in ad_sets:\n",
    "        print(f\"  - Ad Set: {ad_set['adset_name']} (ID: {ad_set['adset_id']})\")\n",
    "else:\n",
    "    print(\"No ad sets found or API access failed. Check your credentials.\")\n",
    "\n",
    "# Get all ads in the campaign\n",
    "print(\"\\nFetching all ads in the campaign...\")\n",
    "all_ads = sensor.get_all_ads()\n",
    "if all_ads:\n",
    "    print(f\"Found {len(all_ads)} ads across all ad sets\")\n",
    "    for ad in all_ads[:5]:  # Show first 5 ads to avoid clutter\n",
    "        print(f\"  - Ad: {ad['ad_name']} (ID: {ad['ad_id']}, Status: {ad['effective_status']})\")\n",
    "    if len(all_ads) > 5:\n",
    "        print(f\"  ... and {len(all_ads) - 5} more ads\")\n",
    "else:\n",
    "    print(\"No ads found or API access failed. Check your credentials.\")\n",
    "\n",
    "# Fetch actual data from the API\n",
    "print(\"\\nFetching actual ad performance data...\")\n",
    "data = sensor.run()\n",
    "\n",
    "# Show campaign level metrics\n",
    "print(\"\\nCampaign level metrics:\")\n",
    "print(f\"  - Purchases: {data['purchases']}\")\n",
    "print(f\"  - Add to Carts: {data['add_to_carts']}\")\n",
    "print(f\"  - Initiated Checkouts: {data['initiated_checkouts']}\")\n",
    "\n",
    "# Show data for a few ads\n",
    "print(\"\\nSample ad-level metrics:\")\n",
    "ad_performances = data.get('ad_performances', {})\n",
    "sample_ads = list(ad_performances.items())[:3]  # Show first 3 ads\n",
    "for ad_id, ad_data in sample_ads:\n",
    "    print(f\"Ad {ad_id} ({ad_data.get('ad_name', 'Unknown')}):\")\n",
    "    print(f\"  - Purchases: {ad_data.get('purchases', 0)}\")\n",
    "    print(f\"  - Add to Carts: {ad_data.get('add_to_carts', 0)}\")\n",
    "    print(f\"  - Impressions: {ad_data.get('impressions', 0)}\")\n",
    "    print(f\"  - Clicks: {ad_data.get('clicks', 0)}\")\n",
    "    print(f\"  - Spend: ${ad_data.get('spend', 0)}\")\n",
    "\n",
    "# Get expected factors to see hierarchical definitions\n",
    "print(\"\\nExamining hierarchical factor definitions:\")\n",
    "expected_factors = sensor.get_expected_factors()\n",
    "\n",
    "# Display hierarchical relationships\n",
    "hierarchical_factors = {name: info for name, info in expected_factors.items() \n",
    "                      if 'hierarchy' in info}\n",
    "\n",
    "print(f\"\\nFound {len(hierarchical_factors)} hierarchical relationships:\")\n",
    "for name, info in hierarchical_factors.items():\n",
    "    hierarchy = info.get('hierarchy', {})\n",
    "    if hierarchy.get('role') == 'aggregate':\n",
    "        print(f\"  - {name} (AGGREGATE): aggregates {hierarchy.get('child_pattern')} using {hierarchy.get('aggregation')}\")\n",
    "    elif hierarchy.get('role') == 'child':\n",
    "        print(f\"  - {name} (CHILD): contributes to {hierarchy.get('parent')}\")\n",
    "\n",
    "# Update the AIcon with sensor data\n",
    "print(\"\\nUpdating AIcon with real sensor data...\")\n",
    "env = {\"use_individual_factors\": True, \"avoid_sampling\": True}  # Simplify for demo purposes\n",
    "aicon.update_from_sensor(\"meta_ads\", environment=env)\n",
    "\n",
    "# Display campaign-level metrics in the state\n",
    "print(\"\\nCampaign-level metrics in state:\")\n",
    "state = aicon.brain.get_state_factors()\n",
    "for key in [\"purchases\", \"add_to_carts\", \"initiated_checkouts\"]:\n",
    "    if key in state:\n",
    "        print(f\"  - {key}: {state[key].get('value')}\")\n",
    "    else:\n",
    "        print(f\"  - {key}: Not in state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Create Action Space and Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new AIcon: Marketing Budget Allocator\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the AIcon classes after reloading\n",
    "from aicons.definitions.simple_bad_aicon import SimpleBadAIcon\n",
    "from aicons.bayesbrainGPT.sensors.tf_sensors import MarketingSensor, WeatherSensor\n",
    "\n",
    "# Create a new AIcon for marketing budget allocation\n",
    "aicon = SimpleBadAIcon(name=\"Marketing Budget Allocator\")\n",
    "print(f\"Created new AIcon: {aicon.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3: Add Sensors (with Auto-Factor Creation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-creating missing factor: base_conversion_rate (continuous)\n",
      "Creating continuous factor with TensorFlow: base_conversion_rate\n",
      "Added continuous factor with TensorFlow distribution: base_conversion_rate\n",
      "Auto-creating missing factor: primary_channel (categorical)\n",
      "Creating categorical factor with TensorFlow: primary_channel\n",
      "Added categorical factor with TensorFlow distribution: primary_channel\n",
      "Auto-creating missing factor: optimal_daily_ads (discrete)\n",
      "Creating discrete factor with TensorFlow: optimal_daily_ads\n",
      "Added discrete factor with TensorFlow distribution: optimal_daily_ads\n",
      "Registered TFSensor: marketing (type: MarketingSensor)\n",
      "Auto-creating missing factor: temperature (continuous)\n",
      "Creating continuous factor with TensorFlow: temperature\n",
      "Added continuous factor with TensorFlow distribution: temperature\n",
      "Auto-creating missing factor: weather_condition (categorical)\n",
      "Creating categorical factor with TensorFlow: weather_condition\n",
      "Added categorical factor with TensorFlow distribution: weather_condition\n",
      "Auto-creating missing factor: precipitation (continuous)\n",
      "Creating continuous factor with TensorFlow: precipitation\n",
      "Added continuous factor with TensorFlow distribution: precipitation\n",
      "Registered TFSensor: weather (type: WeatherSensor)\n",
      "\n",
      "AIcon State after adding sensors:\n",
      "AIcon State (6 factors):\n",
      "\n",
      "base_conversion_rate:\n",
      "  Type: continuous\n",
      "  Distribution: normal\n",
      "  Current value: 0.05\n",
      "  Mean: 0.05\n",
      "  Uncertainty: 0.01\n",
      "  Constraints: >= 0.0, <= 1.0\n",
      "  Description: Base conversion rate for ads\n",
      "\n",
      "primary_channel:\n",
      "  Type: categorical\n",
      "  Distribution: categorical\n",
      "  Current value: facebook\n",
      "  Categories (probability):\n",
      "    facebook: 0.25\n",
      "    google: 0.25\n",
      "    tiktok: 0.25\n",
      "    instagram: 0.25\n",
      "  Description: Primary marketing channel\n",
      "\n",
      "optimal_daily_ads:\n",
      "  Type: discrete\n",
      "  Distribution: categorical\n",
      "  Current value: 5\n",
      "  Possible values: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "  Description: Optimal number of daily ads\n",
      "\n",
      "temperature:\n",
      "  Type: continuous\n",
      "  Distribution: normal\n",
      "  Current value: 22.0\n",
      "  Mean: 22.0\n",
      "  Uncertainty: 1.0\n",
      "  Constraints: >= -50.0, <= 60.0\n",
      "  Description: Temperature in Celsius\n",
      "\n",
      "weather_condition:\n",
      "  Type: categorical\n",
      "  Distribution: categorical\n",
      "  Current value: sunny\n",
      "  Categories (probability):\n",
      "    sunny: 0.17\n",
      "    cloudy: 0.17\n",
      "    rainy: 0.17\n",
      "    snowy: 0.17\n",
      "    foggy: 0.17\n",
      "    stormy: 0.17\n",
      "  Description: Current weather condition\n",
      "\n",
      "precipitation:\n",
      "  Type: continuous\n",
      "  Distribution: normal\n",
      "  Current value: 0.0\n",
      "  Mean: 0.0\n",
      "  Uncertainty: 0.5\n",
      "  Constraints: >= 0.0, <= 100.0\n",
      "  Description: Precipitation amount in mm\n"
     ]
    }
   ],
   "source": [
    "# Register sensors - this will automatically create the necessary factors\n",
    "marketing_sensor = MarketingSensor()\n",
    "aicon.add_sensor(\"marketing\", marketing_sensor)\n",
    "\n",
    "weather_sensor = WeatherSensor()\n",
    "aicon.add_sensor(\"weather\", weather_sensor)\n",
    "\n",
    "# Display all the factors that were automatically created\n",
    "print(\"\\nAIcon State after adding sensors:\")\n",
    "print(aicon.get_state(format_nicely=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4: Create the Action Space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created marketing action space with 3 dimensions\n",
      "\n",
      "Action space created\n",
      "Number of dimensions: 3\n",
      "Dimensions: ['search_budget', 'display_budget', 'social_budget']\n"
     ]
    }
   ],
   "source": [
    "# Define the action space for our decision problem\n",
    "aicon.create_action_space(\n",
    "    space_type='marketing',\n",
    "    total_budget=1000.0,\n",
    "    num_ads=3,\n",
    "    budget_step=10.0,\n",
    "    min_budget=50.0,\n",
    "    ad_names=['search', 'display', 'social']\n",
    ")\n",
    "\n",
    "print(\"\\nAction space created\")\n",
    "print(f\"Number of dimensions: {len(aicon.action_space.dimensions)}\")\n",
    "print(f\"Dimensions: {[dim.name for dim in aicon.action_space.dimensions]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5: Create the Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created weather_dependent_marketing_roi utility function: Marketing ROI Utility\n",
      "Description: Calculates ROI with weather condition adjustments\n",
      "\n",
      "Utility function created\n",
      "Type: Marketing ROI Utility\n",
      "Description: Calculates ROI with weather condition adjustments\n"
     ]
    }
   ],
   "source": [
    "# Define our utility function (what we're trying to maximize)\n",
    "aicon.create_utility_function(\n",
    "    utility_type='weather_dependent_marketing_roi',\n",
    "    revenue_per_sale=15.0,\n",
    "    \n",
    "    # Define how weather affects different ad channels\n",
    "    weather_effects={\n",
    "        'sunny': {'search': 1.0, 'display': 0.8, 'social': 1.2},\n",
    "        'rainy': {'search': 1.1, 'display': 1.2, 'social': 0.9},\n",
    "        'cloudy': {'search': 1.2, 'display': 1.0, 'social': 0.8},\n",
    "        'snowy': {'search': 0.9, 'display': 0.7, 'social': 1.1}\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\nUtility function created\")\n",
    "print(f\"Type: {aicon.utility_function.name}\")\n",
    "print(f\"Description: {aicon.utility_function.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 6: Run Perception to Update Beliefs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running perception update...\n",
      "Running single perception update...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate tuple (not \"float\") to tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Run a single perception update to incorporate the data\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mRunning perception update...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43maicon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43monce\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m=\u001b[49m\u001b[43msimulated_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Check if we have posterior samples\u001b[39;00m\n\u001b[32m     19\u001b[39m posterior_samples = aicon.get_posterior_samples()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Babel/aicons/definitions/simple_bad_aicon.py:666\u001b[39m, in \u001b[36mSimpleBadAIcon.run\u001b[39m\u001b[34m(self, mode, sensor_name, interval, duration, environment)\u001b[39m\n\u001b[32m    664\u001b[39m     success = \u001b[38;5;28mself\u001b[39m.update_from_sensor(sensor_name, environment)\n\u001b[32m    665\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m666\u001b[39m     success = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mupdate_from_all_sensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    668\u001b[39m end_time = time.time()\n\u001b[32m    670\u001b[39m \u001b[38;5;66;03m# Record stats\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Babel/aicons/definitions/simple_bad_aicon.py:416\u001b[39m, in \u001b[36mSimpleBadAIcon.update_from_all_sensors\u001b[39m\u001b[34m(self, environment)\u001b[39m\n\u001b[32m    413\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo sensors registered yet. Add sensors with add_sensor() first.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mperception\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Babel/aicons/bayesbrainGPT/perception/perception.py:959\u001b[39m, in \u001b[36mBayesianPerception.update_all\u001b[39m\u001b[34m(self, environment)\u001b[39m\n\u001b[32m    949\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    950\u001b[39m \u001b[33;03mUpdate state using data from all sensors.\u001b[39;00m\n\u001b[32m    951\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    956\u001b[39m \u001b[33;03m    True if update was successful\u001b[39;00m\n\u001b[32m    957\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    958\u001b[39m \u001b[38;5;66;03m# Collect data from all sensors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m959\u001b[39m observations = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollect_sensor_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m observations:\n\u001b[32m    962\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNo observations from sensors\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Babel/aicons/bayesbrainGPT/perception/perception.py:103\u001b[39m, in \u001b[36mBayesianPerception.collect_sensor_data\u001b[39m\u001b[34m(self, environment)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msensors\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtf_sensors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TFSensor\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sensor, TFSensor):\n\u001b[32m    102\u001b[39m     \u001b[38;5;66;03m# Use TFSensor's get_data method\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     data = \u001b[43msensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCollected data from TFSensor: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    106\u001b[39m     \u001b[38;5;66;03m# Backward compatibility for sensor functions\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Babel/aicons/bayesbrainGPT/sensors/tf_sensors.py:146\u001b[39m, in \u001b[36mTFSensor.get_data\u001b[39m\u001b[34m(self, environment)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[33;03mGet data from this sensor with reliability scores.\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    143\u001b[39m \u001b[33;03m    Dictionary mapping factor names to (value, reliability) tuples\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[38;5;66;03m# If streaming, use latest data, otherwise fetch new data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m data = \u001b[38;5;28mself\u001b[39m.latest_data \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.streaming \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfetch_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[38;5;66;03m# Apply factor mapping and add reliability scores\u001b[39;00m\n\u001b[32m    149\u001b[39m mapped_data = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Babel/aicons/bayesbrainGPT/sensors/tf_sensors.py:263\u001b[39m, in \u001b[36mMarketingSensor.fetch_data\u001b[39m\u001b[34m(self, environment)\u001b[39m\n\u001b[32m    261\u001b[39m     true_rate = true_values.get(\u001b[33m\"\u001b[39m\u001b[33mbase_conversion_rate\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0.05\u001b[39m)\n\u001b[32m    262\u001b[39m     conv_noise = np.random.normal(\u001b[32m0\u001b[39m, \u001b[32m0.005\u001b[39m)  \u001b[38;5;66;03m# Small Gaussian noise\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m     observed_rate = \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\u001b[43mtrue_rate\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_noise\u001b[49m, \u001b[32m0\u001b[39m), \u001b[32m1\u001b[39m)\n\u001b[32m    264\u001b[39m     observations[\u001b[33m\"\u001b[39m\u001b[33mbase_conversion_rate\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mfloat\u001b[39m(observed_rate)\n\u001b[32m    266\u001b[39m \u001b[38;5;66;03m# Add noise to best channel\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: can only concatenate tuple (not \"float\") to tuple"
     ]
    }
   ],
   "source": [
    "# Create simulated data for our sensors\n",
    "simulated_data = {\n",
    "    # Marketing data\n",
    "    \"base_conversion_rate\": (0.05, 0.9),\n",
    "    \"primary_channel\": (\"social\", 0.8),\n",
    "    \"optimal_daily_ads\": (12, 0.7),\n",
    "    \n",
    "    # Weather data\n",
    "    \"temperature\": (23.5, 0.95),\n",
    "    \"weather_condition\": (\"sunny\", 0.9),\n",
    "    \"precipitation\": (0.0, 0.95)\n",
    "}\n",
    "\n",
    "# Run a single perception update to incorporate the data\n",
    "print(\"\\nRunning perception update...\")\n",
    "aicon.run(mode='once', environment=simulated_data)\n",
    "\n",
    "# Check if we have posterior samples\n",
    "posterior_samples = aicon.get_posterior_samples()\n",
    "if posterior_samples:\n",
    "    print(\"\\nPosterior samples available for factors:\")\n",
    "    for factor_name in posterior_samples:\n",
    "        samples = posterior_samples[factor_name]\n",
    "        if isinstance(samples, np.ndarray) and samples.size > 0:\n",
    "            print(f\"  {factor_name}: {len(samples)} samples, mean={np.mean(samples):.4f}\")\n",
    "else:\n",
    "    print(\"\\nNo posterior samples available. Check for errors in the perception update.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules reloaded successfully\n",
      "Auto-creating missing factor: base_conversion_rate (continuous)\n",
      "Creating continuous factor with TensorFlow: base_conversion_rate\n",
      "Added continuous factor with TensorFlow distribution: base_conversion_rate\n",
      "Auto-creating missing factor: primary_channel (categorical)\n",
      "Creating categorical factor with TensorFlow: primary_channel\n",
      "Added categorical factor with TensorFlow distribution: primary_channel\n",
      "Auto-creating missing factor: optimal_daily_ads (discrete)\n",
      "Creating discrete factor with TensorFlow: optimal_daily_ads\n",
      "Added discrete factor with TensorFlow distribution: optimal_daily_ads\n",
      "Registered TFSensor: marketing (type: MarketingSensor)\n",
      "\n",
      "Running perception update...\n",
      "Running single perception update...\n",
      "DEBUG - Inside collect_sensor_data\n",
      "DEBUG - Environment type: <class 'dict'>\n",
      "DEBUG - Environment keys: ['base_conversion_rate', 'primary_channel', 'optimal_daily_ads']\n",
      "DEBUG - base_conversion_rate value: 0.05\n",
      "DEBUG - base_conversion_rate type: <class 'float'>\n",
      "DEBUG - About to call sensor.get_data(environment) for sensor: marketing\n",
      "DEBUG - Inside marketing.get_data()\n",
      "DEBUG - Environment type: <class 'dict'>\n",
      "DEBUG - Environment keys: ['base_conversion_rate', 'primary_channel', 'optimal_daily_ads']\n",
      "DEBUG - Inside MarketingSensor.fetch_data\n",
      "DEBUG - Environment type: <class 'dict'>\n",
      "DEBUG - Environment keys: ['base_conversion_rate', 'primary_channel', 'optimal_daily_ads']\n",
      "DEBUG - base_conversion_rate value: 0.05\n",
      "DEBUG - base_conversion_rate type: <class 'float'>\n",
      "DEBUG - After fetch_data, data: {'base_conversion_rate': 0.044459304368994326, 'primary_channel': np.str_('facebook'), 'optimal_daily_ads': 13}\n",
      "DEBUG - Final mapped_data with reliability: {'base_conversion_rate': (0.044459304368994326, 0.9), 'primary_channel': (np.str_('facebook'), 0.7), 'optimal_daily_ads': (13, 0.8)}\n",
      "Collected data from TFSensor: marketing\n",
      "  Factor: base_conversion_rate → base_conversion_rate, Value: 0.044459304368994326, Reliability: 0.9\n",
      "  Factor: primary_channel → primary_channel, Value: facebook, Reliability: 0.7\n",
      "  Factor: optimal_daily_ads → optimal_daily_ads, Value: 13, Reliability: 0.8\n",
      "Sampling posterior distribution...\n",
      "Setting up MCMC sampling for 3 observations...\n",
      "Running MCMC sampling...\n",
      "Error in MCMC sampling: Graph execution error:\n",
      "\n",
      "Detected at node mcmc_sample_chain/trace_scan/while/smart_for_loop/while/simple_step_size_adaptation___init__/_one_step/mh_one_step/hmc_kernel_one_step/leapfrog_integrate/while/leapfrog_integrate_one_step/maybe_call_fn_and_grads/value_and_gradients/value_and_gradient/JointDistributionNamed_CONSTRUCTED_AT_top_level/log_prob/Categorical/log_prob/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.7_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.7_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.7_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n",
      "\n",
      "  File \"/var/folders/49/05_8nzt57sd6nmpszgklp43r0000gn/T/ipykernel_65110/2527428984.py\", line 32, in <module>\n",
      "\n",
      "  File \"/Users/infa/Documents/Babel/aicons/definitions/simple_bad_aicon.py\", line 666, in run\n",
      "\n",
      "  File \"/Users/infa/Documents/Babel/aicons/definitions/simple_bad_aicon.py\", line 416, in update_from_all_sensors\n",
      "\n",
      "  File \"/Users/infa/Documents/Babel/aicons/bayesbrainGPT/perception/perception.py\", line 976, in update_all\n",
      "\n",
      "  File \"/Users/infa/Documents/Babel/aicons/bayesbrainGPT/perception/perception.py\", line 533, in sample_posterior\n",
      "\n",
      "  File \"/Users/infa/Documents/Babel/aicons/bayesbrainGPT/perception/perception.py\", line 524, in run_mcmc\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/sample.py\", line 359, in sample_chain\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/internal/loop_util.py\", line 232, in trace_scan\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/internal/loop_util.py\", line 222, in _body\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/sample.py\", line 352, in _trace_scan_fn\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/internal/loop_util.py\", line 111, in smart_for_loop\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/internal/loop_util.py\", line 113, in <lambda>\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/sample.py\", line 349, in _seeded_one_step\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/simple_step_size_adaptation.py\", line 354, in one_step\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/hmc.py\", line 527, in one_step\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/metropolis_hastings.py\", line 191, in one_step\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/hmc.py\", line 705, in one_step\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/internal/leapfrog_integrator.py\", line 291, in __call__\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/internal/leapfrog_integrator.py\", line 293, in <lambda>\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/internal/leapfrog_integrator.py\", line 336, in _one_step\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/internal/util.py\", line 297, in maybe_call_fn_and_grads\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/internal/util.py\", line 265, in _value_and_gradients\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/math/gradient.py\", line 108, in value_and_gradient\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/math/gradient.py\", line 378, in _value_and_grad_impl\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/math/gradient.py\", line 330, in _gradient_old\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/math/gradient.py\", line 378, in <lambda>\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/math/gradient.py\", line 375, in <lambda>\n",
      "\n",
      "  File \"/Users/infa/Documents/Babel/aicons/bayesbrainGPT/perception/perception.py\", line 347, in target_log_prob_fn\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 899, in log_prob\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1269, in _call_log_prob\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 677, in _log_prob\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 742, in _map_measure_over_dists\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 850, in _call_execute_model\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 1005, in _execute_model\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 748, in <lambda>\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 740, in <lambda>\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1287, in log_prob\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1269, in _call_log_prob\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/distributions/categorical.py\", line 312, in _log_prob\n",
      "\n",
      "Received a label value of 4 which is outside the valid range of [0, 4).  Label values: 4\n",
      "\t [[{{node mcmc_sample_chain/trace_scan/while/smart_for_loop/while/simple_step_size_adaptation___init__/_one_step/mh_one_step/hmc_kernel_one_step/leapfrog_integrate/while/leapfrog_integrate_one_step/maybe_call_fn_and_grads/value_and_gradients/value_and_gradient/JointDistributionNamed_CONSTRUCTED_AT_top_level/log_prob/Categorical/log_prob/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_run_mcmc_3817]\n",
      "No posterior samples available\n",
      "Perception update completed. Success: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 12:58:14.809553: W tensorflow/core/framework/op_kernel.cc:1841] OP_REQUIRES failed at sparse_xent_op.cc:103 : INVALID_ARGUMENT: Received a label value of 4 which is outside the valid range of [0, 4).  Label values: 4\n",
      "2025-03-13 12:58:14.809569: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Received a label value of 4 which is outside the valid range of [0, 4).  Label values: 4\n",
      "\t [[{{function_node mcmc_sample_chain_trace_scan_while_smart_for_loop_while_simple_step_size_adaptation___init____one_step_mh_one_step_hmc_kernel_one_step_leapfrog_integrate_while_body_2688}}{{node mcmc_sample_chain/trace_scan/while/smart_for_loop/while/simple_step_size_adaptation___init__/_one_step/mh_one_step/hmc_kernel_one_step/leapfrog_integrate/while/leapfrog_integrate_one_step/maybe_call_fn_and_grads/value_and_gradients/value_and_gradient/JointDistributionNamed_CONSTRUCTED_AT_top_level/log_prob/Categorical/log_prob/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/infa/Documents/Babel/aicons/bayesbrainGPT/perception/perception.py\", line 533, in sample_posterior\n",
      "    samples, is_accepted = run_mcmc()\n",
      "                           ^^^^^^^^^^\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
      "    except TypeError as e:\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\n",
      "Detected at node mcmc_sample_chain/trace_scan/while/smart_for_loop/while/simple_step_size_adaptation___init__/_one_step/mh_one_step/hmc_kernel_one_step/leapfrog_integrate/while/leapfrog_integrate_one_step/maybe_call_fn_and_grads/value_and_gradients/value_and_gradient/JointDistributionNamed_CONSTRUCTED_AT_top_level/log_prob/Categorical/log_prob/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.7_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.7_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.7_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n",
      "\n",
      "  File \"/var/folders/49/05_8nzt57sd6nmpszgklp43r0000gn/T/ipykernel_65110/2527428984.py\", line 32, in <module>\n",
      "\n",
      "  File \"/Users/infa/Documents/Babel/aicons/definitions/simple_bad_aicon.py\", line 666, in run\n",
      "\n",
      "  File \"/Users/infa/Documents/Babel/aicons/definitions/simple_bad_aicon.py\", line 416, in update_from_all_sensors\n",
      "\n",
      "  File \"/Users/infa/Documents/Babel/aicons/bayesbrainGPT/perception/perception.py\", line 976, in update_all\n",
      "\n",
      "  File \"/Users/infa/Documents/Babel/aicons/bayesbrainGPT/perception/perception.py\", line 533, in sample_posterior\n",
      "\n",
      "  File \"/Users/infa/Documents/Babel/aicons/bayesbrainGPT/perception/perception.py\", line 524, in run_mcmc\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/sample.py\", line 359, in sample_chain\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/internal/loop_util.py\", line 232, in trace_scan\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/internal/loop_util.py\", line 222, in _body\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/sample.py\", line 352, in _trace_scan_fn\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/internal/loop_util.py\", line 111, in smart_for_loop\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/internal/loop_util.py\", line 113, in <lambda>\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/sample.py\", line 349, in _seeded_one_step\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/simple_step_size_adaptation.py\", line 354, in one_step\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/hmc.py\", line 527, in one_step\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/metropolis_hastings.py\", line 191, in one_step\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/hmc.py\", line 705, in one_step\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/internal/leapfrog_integrator.py\", line 291, in __call__\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/internal/leapfrog_integrator.py\", line 293, in <lambda>\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/internal/leapfrog_integrator.py\", line 336, in _one_step\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/internal/util.py\", line 297, in maybe_call_fn_and_grads\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/mcmc/internal/util.py\", line 265, in _value_and_gradients\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/math/gradient.py\", line 108, in value_and_gradient\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/math/gradient.py\", line 378, in _value_and_grad_impl\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/math/gradient.py\", line 330, in _gradient_old\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/math/gradient.py\", line 378, in <lambda>\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/math/gradient.py\", line 375, in <lambda>\n",
      "\n",
      "  File \"/Users/infa/Documents/Babel/aicons/bayesbrainGPT/perception/perception.py\", line 347, in target_log_prob_fn\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 899, in log_prob\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1269, in _call_log_prob\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 677, in _log_prob\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 742, in _map_measure_over_dists\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 850, in _call_execute_model\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 1005, in _execute_model\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 748, in <lambda>\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\", line 740, in <lambda>\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1287, in log_prob\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1269, in _call_log_prob\n",
      "\n",
      "  File \"/Users/infa/Library/Caches/pypoetry/virtualenvs/babel-PAVoc7qP-py3.12/lib/python3.12/site-packages/tensorflow_probability/python/distributions/categorical.py\", line 312, in _log_prob\n",
      "\n",
      "Received a label value of 4 which is outside the valid range of [0, 4).  Label values: 4\n",
      "\t [[{{node mcmc_sample_chain/trace_scan/while/smart_for_loop/while/simple_step_size_adaptation___init__/_one_step/mh_one_step/hmc_kernel_one_step/leapfrog_integrate/while/leapfrog_integrate_one_step/maybe_call_fn_and_grads/value_and_gradients/value_and_gradient/JointDistributionNamed_CONSTRUCTED_AT_top_level/log_prob/Categorical/log_prob/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_run_mcmc_3817]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'iterations': 1,\n",
       " 'start_time': datetime.datetime(2025, 3, 13, 12, 58, 13, 804370),\n",
       " 'last_update_time': datetime.datetime(2025, 3, 13, 12, 58, 14, 842360),\n",
       " 'updates': [{'time': datetime.datetime(2025, 3, 13, 12, 58, 14, 842364),\n",
       "   'success': False,\n",
       "   'sensor': 'all',\n",
       "   'duration_sec': 1.0378880500793457}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload modules to pick up our debug statements\n",
    "import importlib\n",
    "import aicons.definitions.simple_bad_aicon\n",
    "import aicons.bayesbrainGPT.sensors.tf_sensors\n",
    "import aicons.bayesbrainGPT.perception.perception\n",
    "\n",
    "importlib.reload(aicons.definitions.simple_bad_aicon)\n",
    "importlib.reload(aicons.bayesbrainGPT.sensors.tf_sensors)\n",
    "importlib.reload(aicons.bayesbrainGPT.perception.perception)\n",
    "print(\"Modules reloaded successfully\")\n",
    "\n",
    "# Setup\n",
    "from aicons.definitions.simple_bad_aicon import SimpleBadAIcon\n",
    "from aicons.bayesbrainGPT.sensors.tf_sensors import MarketingSensor\n",
    "\n",
    "# Create AIcon\n",
    "aicon = SimpleBadAIcon(name=\"Marketing Budget Allocator\")\n",
    "\n",
    "# Add sensors\n",
    "marketing_sensor = MarketingSensor()\n",
    "aicon.add_sensor(\"marketing\", marketing_sensor)\n",
    "\n",
    "# Create simulated data - just raw values\n",
    "simulated_data = {\n",
    "    \"base_conversion_rate\": 0.05,  # Using raw value (not a tuple)\n",
    "    \"primary_channel\": \"social\",\n",
    "    \"optimal_daily_ads\": 12\n",
    "}\n",
    "\n",
    "# Run with debug tracing active\n",
    "print(\"\\nRunning perception update...\")\n",
    "aicon.run(mode='once', environment=simulated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "babel-PAVoc7qP-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
